Machine Learning Class Syllabus


##Introduction to Machine Learning

1. What, why, how, and challenges
2. Differences between stats, ML, and econometrics

References: [1] Chapter 1


##Introduction to Python

1. Functions, Lists, Dictionaries, Counters, Sets, List Comprehensions, Generators
2. Data science stack: numpy, pandas, scikit-learn, scipy, jupyter notebooks
3. Git and github

References: [2] Chapter 2, [3] All Chapters


##Review of Linear Algebra and Stats

1. Vectors, Matrices, CLT, Hypothesis Testing, and Bayes Theorem

References: [2] Chapters 4-7


##How to get and clean data

1. Loading from text, SQL, and web pages
2. Cleaning data: missing, outliers, scaling data, reformatting

References: [3] Chapters 5-7, [2] Chapters 9-10 and 23, [1] Chapter 2


##How to visualize and describe data

1. Data description techniques: mean, median, percentiles, correlations
2. Data visualization techniques: various plots, Bokeh

References: [1] Chapter 2, [2] Chapters 3 and 5, [3] Chapters 5, 8 and 9


##Regression

1. Linear Regression
2. Logistic Regression
3. Regularized Regression

References: [2] Chapters 14-16, [1] Chapter 4, [4] Chapter 3, [5] Weeks 1-3


##Gradient Descent

1. Cost functions, learning rates, and gradients

References: [2] Chapter 8, [1] Chapter 4


##How to evaluate and tune models

1. Training/Testing and Cross validation
2. MSE
3. Confusion matrix, precision and recall, ROC
4. Learning Curves
5. Bias and variance / over-fitting under-fitting
6. Tuning hyperparameters
7. Feature importances

References: [2] Chapter 11, [1] Chapter 2 and 3, [4] Chapter 2, 5, [5] Week 6


##Classification Models

1. Naive Bayes, K-nearest neighbors

References: [2] Chapters 12-13, [4] Chapter 4 

SVMs

1. Max-margin, kernel trick, more than 2 classes

References: [1] Chapter 5, [4] Chapter 9, [5] Week 7


Trees and Ensembles

1. Decision Trees, Random Forests, and Gradient Boosted Trees
2. XGBoost
3. Stacking

References: [2] Chapter 17, [1] Chapters 6-7, [4] Chapter 8


Dimensionality Reduction

1. Curse of dimensionality
2. PCA and SVD
3. Feature subset selection
4. Regularization
5. T-SNE

References: [1] Chapter 8, [7]. [4] Chapter 6, 10, [5] Week 8


Clustering

1. K-means, Hierarchical, DBScan

References: [2] Chapter 19, [4] Chapter 10, [5] Week 8


Recommender Systems

1. Collaborative filtering and deep collaborative filtering

References: [2] Chapter 22, [5] Week 9



Anomaly Detection

1. Gaussian Distributions
2. Treat as classification, forecasting, or clustering

References: [5] Week 9


Network Analysis

1. Page rank

References: [2] Chapter 21


Data Science at Scale

1. Parallelism - dask and blaze
2. Spark and Mapreduce
3. AWS
4. Online learning and stochastic gradient descent

References: [5] Week 10, [2] Chapter 24


Deep Learning

1. Perceptron, simple networks, and backprop
2. GPUs
3. Tensorflow, Keras, Pytorch
4. CNNs
5. RNNs and word2vec
6. Autoencoders
7. Reinforcement Learning

References: [2] Chapter 18, [1] Chapters 9-16, [5] Weeks 4-5, [6] All Lessons


Machine Learning in Industry

1. Guest lecturers / companies
2. Things Kaggle challenges won’t teach you
3. Why most data science initiatives fail
4. Importance of communication and collaboration
5. Choosing metrics in industry



References:

1. Hands-On Machine Learning with Scikit-Learn and Tensorflow
2. Data Science From Scratch
3. Python for Data Analysis
4. Introduction to Statistical Learning
5. Coursera: Machine Learning
6. Fastai course 1
7. https://distill.pub/2016/misread-tsne/
