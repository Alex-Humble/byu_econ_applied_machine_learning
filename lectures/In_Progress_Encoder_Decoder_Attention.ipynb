{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #put a space between punctuation, so not included in word\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #remove things that are not letters or punctuation\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    # basically removes non-english standard alphabet letters and replaces with equivalent.\n",
    "    # so no accented letters => less to learn\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def readLangs(input_file_location, lang1_name=\"English\", lang2_name=\"French\"):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(input_file_location, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    input_lang = Lang(lang1_name)\n",
    "    output_lang = Lang(lang2_name)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make learning easier, we will limit to sentences less than max length \n",
    "# in either language\n",
    "# And only take sentences that start with certain prefixes\n",
    "# Removed punctuation b/c filtered out in our normalize function\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def prepareData(input_file_location, lang1_name=\"English\", \n",
    "                lang2_name=\"French\"):\n",
    "    input_lang, output_lang, pairs = readLangs(input_file_location, lang1_name,\n",
    "                                              lang2_name)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start of sentence\n",
    "SOS_token = 0\n",
    "# end of sentence\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 149861 sentence pairs\n",
      "Trimmed to 11589 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "English 3016\n",
      "French 4634\n",
      "['we re in love .', 'nous nous aimons .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(\"../../../data/text/fra-eng/fra.txt\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple encoder network that embeds the character and then feeds through a GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attn Decoder\n",
    "    1. Need max length because learning which input words to attend to\n",
    "    And thus need to know the maximum number of words could attend to\n",
    "    2. The attn_weights tell us how much to weight each input word - in this case French,\n",
    "       In order to predict the english word.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # note input and output same size\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.attn_layer = nn.Linear(2 * self.hidden_size, MAX_LENGTH)\n",
    "        self.out_layer = nn.Linear(self.hidden_size, input_size)\n",
    "        self.attn_combined_layer = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn = self.attn_layer(torch.cat((embedded[0], hidden[0]),dim=1))\n",
    "        attn_weights = self.softmax(attn)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), \n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        attn_combined = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        attn_combined = self.relu(self.attn_combined_layer(attn_combined).unsqueeze(0))\n",
    "        output, hidden = self.gru(attn_combined, hidden)\n",
    "        output = self.softmax(self.out_layer(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "         decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros((MAX_LENGTH, encoder.hidden_size)))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # Here we are feeding in the english words to get the final hidden state \n",
    "    # for the decoder\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[:,i,:], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_ouput[0][0]\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    # Here we take the final hidden state from the encoder\n",
    "    # And feed it to decoder\n",
    "    # We also give decoder the word to predict the next word starting with SOS token\n",
    "    # If use teacher forcing then give it the truth, otherwise give it prediction\n",
    "    if use_teacher_forcing:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                          encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[i])\n",
    "            decoder_input = target_variable[i]\n",
    "            \n",
    "    else:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                           encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[i])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            top_predicted = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[top_predicted]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            if top_predicted == EOS_token:\n",
    "                break\n",
    "                \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, data_loader, epochs, print_every=1000, plot_every=100,\n",
    "               learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    iter = 1\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for i_batch, sample_batched in enumerate(data_loader):\n",
    "            \n",
    "            loss = train(Variable(sample_batched[0]), Variable(sample_batched[1]), encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            iter = iter + 1\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, input_lang, output_lang, max_length):\n",
    "        self.data = data\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data[index]\n",
    "        training_pairs = self.tensorFromPair(row)\n",
    "        return (training_pairs[0], training_pairs[1])\n",
    "    \n",
    "    def indexesFromSentence(self, lang, sentence):\n",
    "        return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "    def tensorFromSentence(self, lang, sentence):\n",
    "        indexes = self.indexesFromSentence(lang, sentence)\n",
    "        indexes.append(EOS_token)\n",
    "        # make it 1 column with number of rows equal to words in sentence\n",
    "        result = torch.LongTensor(indexes).view(-1, 1)\n",
    "        pad_amount = MAX_LENGTH - result.size(0)\n",
    "        if pad_amount > 0:\n",
    "            result = F.pad(result, (0,0,0,pad_amount), value=EOS_token).data\n",
    "        result = result.cuda() if use_cuda else result\n",
    "        return result\n",
    "\n",
    "    def tensorFromPair(self, pair):\n",
    "        input_variable = self.tensorFromSentence(self.input_lang, pair[0])\n",
    "        output_variable = self.tensorFromSentence(self.output_lang, pair[1])\n",
    "        return (input_variable, output_variable)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "batch_size = 8\n",
    "training_dataset = CustomDataset(pairs, input_lang, output_lang, MAX_LENGTH)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 8 and 1 in dimension 0 at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THC/generic/THCTensorMath.cu:111",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-c8d2f95f8d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-8b6adc8e8011>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, data_loader, epochs, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             loss = train(Variable(sample_batched[0]), Variable(sample_batched[1]), encoder,\n\u001b[0;32m---> 17\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-bc815d149178>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     36\u001b[0m             decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n\u001b[1;32m     37\u001b[0m                                                                            \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                                                           encoder_outputs)\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-c1a1c790d314>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         attn_applied = torch.bmm(attn_weights.unsqueeze(0), \n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 8 and 1 in dimension 0 at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THC/generic/THCTensorMath.cu:111"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, batch_size)\n",
    "decoder = AttnDecoderRNN(output_lang.n_words, hidden_size)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "trainIters(encoder, decoder, training_dataloader, 8, print_every=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"../models/attn_encoder.state\")\n",
    "torch.save(decoder.state_dict(), \"../models/attn_decoder.state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[i], encoder_hidden)\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoded_words = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden = decoder.forward(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        top_predicted = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[top_predicted]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if top_predicted == EOS_token:\n",
    "            decoded_words.append(\"<EOS>\")\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[top_predicted])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        print(\"<\", \" \".join(output_words))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(encoder, decoder, \"i m going to teach .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
