{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "\n",
    "### APIs\n",
    "\n",
    "### SQL\n",
    "\n",
    "### Scraping\n",
    "\n",
    "\n",
    "## Cleaning Data\n",
    "\n",
    "### re-scaling\n",
    "\n",
    "### missing - understand why and magintude. Knn vs Median vs ..\n",
    "\n",
    "### outliers\n",
    "\n",
    "### text and categorical\n",
    "\n",
    "### Sklearn pipelines\n",
    "\n",
    "\n",
    "## Describing Data\n",
    "\n",
    "### Pandas describe, info, value_counts, correlation matrix (and limits - Simpson;s paradox, etc. DS f S)\n",
    "\n",
    "### mean, median and percentiles, std_dev\n",
    "\n",
    "### group by and pivot tables, reshape, and cross tab\n",
    "\n",
    "\n",
    "## Visualizing Data\n",
    "\n",
    "### matplotlib and seaborn\n",
    "\n",
    "### Histogram, line, data aware, bar, and scatter\n",
    "\n",
    "### Geo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting Data\n",
    "\n",
    "One of the first steps for a machine learning project is getting the data! In industry, this can sometimes be more difficult that it sounds. :)\n",
    "\n",
    "In this section we will review some of the most common ways of accessing data and some sources of data.\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "* [Kaggle](https://www.kaggle.com)\n",
    "* [UCI](https://archive.ics.uci.edu/ml/datasets.html)\n",
    "* [Awesome Public Data Sets](https://github.com/caesar0301/awesome-public-datasets)\n",
    "* A website via web scraping\n",
    "* A website's API\n",
    "\n",
    "### Reading in CSV files\n",
    "\n",
    "CSV files are extremely common in machine learning. These files have a row of data per line of the file and each line is a comma seperated list in which each element is a column. Pandas makes it extremely easy to read in these data.\n",
    "\n",
    "The documentation can be found [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). A few parameters of note:\n",
    "\n",
    "1. sep - this defaults to a comma, but we can specify anything we want. For example, CSV format is poor if some of your columns contain commas. A better option might be a |.\n",
    "2. header - which row (if any) have the column names.\n",
    "3. names - column names to use\n",
    "\n",
    "If your CSV is well formatted with the first row being the column names, then the default parameters should work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'educationnum', 'maritalstatus', 'occupation', 'relationship', 'race',\n",
    "        'sex', 'capitalgain', 'capitalloss', 'hoursperweek', 'nativecountry', 'label']\n",
    "train_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "                      header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educationnum</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>nativecountry</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  educationnum  \\\n",
       "0   39          State-gov   77516   Bachelors            13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors            13   \n",
       "2   38            Private  215646     HS-grad             9   \n",
       "3   53            Private  234721        11th             7   \n",
       "4   28            Private  338409   Bachelors            13   \n",
       "\n",
       "         maritalstatus          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek   nativecountry   label  \n",
       "0         2174            0            40   United-States   <=50K  \n",
       "1            0            0            13   United-States   <=50K  \n",
       "2            0            0            40   United-States   <=50K  \n",
       "3            0            0            40   United-States   <=50K  \n",
       "4            0            0            40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON\n",
    "\n",
    "JSON is also a very popular format as it allows for a more flexible schema. A lot of the data sent around the web is transmitted as JSON. Here is an example:\n",
    "```text\n",
    "{\n",
    "    \"glossary\": {\n",
    "        \"title\": \"example glossary\",\n",
    "\t\t\"GlossDiv\": {\n",
    "            \"title\": \"S\",\n",
    "\t\t\t\"GlossList\": {\n",
    "                \"GlossEntry\": {\n",
    "                    \"ID\": \"SGML\",\n",
    "\t\t\t\t\t\"SortAs\": \"SGML\",\n",
    "\t\t\t\t\t\"GlossTerm\": \"Standard Generalized Markup Language\",\n",
    "\t\t\t\t\t\"Acronym\": \"SGML\",\n",
    "\t\t\t\t\t\"Abbrev\": \"ISO 8879:1986\",\n",
    "\t\t\t\t\t\"GlossDef\": {\n",
    "                        \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n",
    "\t\t\t\t\t\t\"GlossSeeAlso\": [\"GML\", \"XML\"]\n",
    "                    },\n",
    "\t\t\t\t\t\"GlossSee\": \"markup\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "Python can actually quite easily read these data from strings into dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = \"\"\"{\n",
    "    \"glossary\": {\n",
    "        \"title\": \"example glossary\",\n",
    "        \"GlossDiv\": {\n",
    "            \"title\": \"S\",\n",
    "            \"GlossList\": {\n",
    "                \"GlossEntry\": {\n",
    "                    \"ID\": \"SGML\",\n",
    "                    \"SortAs\": \"SGML\",\n",
    "                    \"GlossTerm\": \"Standard Generalized Markup Language\",\n",
    "                    \"Acronym\": \"SGML\",\n",
    "                    \"Abbrev\": \"ISO 8879:1986\",\n",
    "                    \"GlossDef\": {\n",
    "                        \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n",
    "                        \"GlossSeeAlso\": [\"GML\", \"XML\"]\n",
    "                    },\n",
    "                    \"GlossSee\": \"markup\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glossary': {'GlossDiv': {'GlossList': {'GlossEntry': {'Abbrev': 'ISO 8879:1986',\n",
       "     'Acronym': 'SGML',\n",
       "     'GlossDef': {'GlossSeeAlso': ['GML', 'XML'],\n",
       "      'para': 'A meta-markup language, used to create markup languages such as DocBook.'},\n",
       "     'GlossSee': 'markup',\n",
       "     'GlossTerm': 'Standard Generalized Markup Language',\n",
       "     'ID': 'SGML',\n",
       "     'SortAs': 'SGML'}},\n",
       "   'title': 'S'},\n",
       "  'title': 'example glossary'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict = json.loads(json_string)\n",
    "json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GlossDiv': {'GlossList': {'GlossEntry': {'Abbrev': 'ISO 8879:1986',\n",
       "    'Acronym': 'SGML',\n",
       "    'GlossDef': {'GlossSeeAlso': ['GML', 'XML'],\n",
       "     'para': 'A meta-markup language, used to create markup languages such as DocBook.'},\n",
       "    'GlossSee': 'markup',\n",
       "    'GlossTerm': 'Standard Generalized Markup Language',\n",
       "    'ID': 'SGML',\n",
       "    'SortAs': 'SGML'}},\n",
       "  'title': 'S'},\n",
       " 'title': 'example glossary'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict[\"glossary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is a somewhat more realistic example. Let's say that we have some data on web page: https://www.ncdc.noaa.gov/cag/time-series/global/globe/land_ocean/ytd/12/1880-2016.json\n",
    "\n",
    "We would like to grab the data directly from the page and put get it into a data frame. First, we need to get the data. The simpliest way is to use the requests package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_request = requests.get(\"https://www.ncdc.noaa.gov/cag/time-series/global/globe/land_ocean/ytd/12/1880-2016.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"description\":{\"title\":\"Global Land and Ocean Temperature Anomalies, January-December\",\"units\":\"Degrees Celsius\",\"base_period\":\"1901-2000\",\"missing\":\"-999.0000\"},\"data\":{\"1880\":\"-0.13\",\"1881\":\"-0.07\",\"1882\":\"-0.07\",\"1883\":\"-0.15\",\"1884\":\"-0.21\",\"1885\":\"-0.22\",\"1886\":\"-0.21\",\"1887\":\"-0.25\",\"1888\":\"-0.15\",\"1889\":\"-0.10\",\"1890\":\"-0.32\",\"1891\":\"-0.25\",\"1892\":\"-0.30\",\"1893\":\"-0.32\",\"1894\":\"-0.28\",\"1895\":\"-0.23\",\"1896\":\"-0.09\",\"1897\":\"-0.12\",\"1898\":\"-0.26\",\"1899\":\"-0.12\",\"1900\":\"-0.07\",\"1901\":\"-0.14\",\"1902\":\"-0.25\",\"1903\":\"-0.34\",\"1904\":\"-0.42\",\"1905\":\"-0.29\",\"1906\":\"-0.22\",\"1907\":\"-0.38\",\"1908\":\"-0.44\",\"1909\":\"-0.43\",\"1910\":\"-0.39\",\"1911\":\"-0.44\",\"1912\":\"-0.33\",\"1913\":\"-0.32\",\"1914\":\"-0.14\",\"1915\":\"-0.07\",\"1916\":\"-0.29\",\"1917\":\"-0.31\",\"1918\":\"-0.20\",\"1919\":\"-0.20\",\"1920\":\"-0.21\",\"1921\":\"-0.14\",\"1922\":\"-0.23\",\"1923\":\"-0.21\",\"1924\":\"-0.25\",\"1925\":\"-0.14\",\"1926\":\"-0.06\",\"1927\":\"-0.15\",\"1928\":\"-0.17\",\"1929\":\"-0.29\",\"1930\":\"-0.10\",\"1931\":\"-0.07\",\"1932\":\"-0.12\",\"1933\":\"-0.25\",\"1934\":\"-0.10\",\"1935\":\"-0.14\",\"1936\":\"-0.11\",\"1937\":\"-0.02\",\"1938\":\"-0.03\",\"1939\":\"-0.01\",\"1940\":\"0.10\",\"1941\":\"0.20\",\"1942\":\"0.15\",\"1943\":\"0.16\",\"1944\":\"0.29\",\"1945\":\"0.17\",\"1946\":\"-0.00\",\"1947\":\"-0.05\",\"1948\":\"-0.05\",\"1949\":\"-0.06\",\"1950\":\"-0.16\",\"1951\":\"-0.01\",\"1952\":\"0.03\",\"1953\":\"0.10\",\"1954\":\"-0.11\",\"1955\":\"-0.13\",\"1956\":\"-0.20\",\"1957\":\"0.05\",\"1958\":\"0.11\",\"1959\":\"0.06\",\"1960\":\"0.02\",\"1961\":\"0.08\",\"1962\":\"0.09\",\"1963\":\"0.11\",\"1964\":\"-0.15\",\"1965\":\"-0.08\",\"1966\":\"-0.02\",\"1967\":\"-0.01\",\"1968\":\"-0.03\",\"1969\":\"0.09\",\"1970\":\"0.04\",\"1971\":\"-0.08\",\"1972\":\"0.03\",\"1973\":\"0.16\",\"1974\":\"-0.07\",\"1975\":\"0.00\",\"1976\":\"-0.08\",\"1977\":\"0.20\",\"1978\":\"0.11\",\"1979\":\"0.23\",\"1980\":\"0.26\",\"1981\":\"0.30\",\"1982\":\"0.18\",\"1983\":\"0.34\",\"1984\":\"0.15\",\"1985\":\"0.14\",\"1986\":\"0.23\",\"1987\":\"0.37\",\"1988\":\"0.38\",\"1989\":\"0.30\",\"1990\":\"0.43\",\"1991\":\"0.40\",\"1992\":\"0.26\",\"1993\":\"0.28\",\"1994\":\"0.34\",\"1995\":\"0.46\",\"1996\":\"0.32\",\"1997\":\"0.52\",\"1998\":\"0.63\",\"1999\":\"0.44\",\"2000\":\"0.42\",\"2001\":\"0.54\",\"2002\":\"0.60\",\"2003\":\"0.61\",\"2004\":\"0.58\",\"2005\":\"0.66\",\"2006\":\"0.61\",\"2007\":\"0.61\",\"2008\":\"0.54\",\"2009\":\"0.64\",\"2010\":\"0.70\",\"2011\":\"0.58\",\"2012\":\"0.63\",\"2013\":\"0.67\",\"2014\":\"0.74\",\"2015\":\"0.90\",\"2016\":\"0.94\"}}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_request.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into too much detail, a GET request basically just goes and grabs the data from the page. You can learn some more [here](https://www.w3schools.com/tags/ref_httpmethods.asp). You can then get the raw text with the .text. From there we can load the text using json.loads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_dict = json.loads(get_request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['description', 'data'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_period': '1901-2000',\n",
       " 'missing': '-999.0000',\n",
       " 'title': 'Global Land and Ocean Temperature Anomalies, January-December',\n",
       " 'units': 'Degrees Celsius'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dict['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(climate_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1880    -0.13\n",
       "1881    -0.07\n",
       "1882    -0.07\n",
       "1883    -0.15\n",
       "1884    -0.21\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we just have one column, we use pandas series functionality as opposed to a data frame. Data frames do have the ability to load [from json](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html) and [dictionaries](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading raw files\n",
    "\n",
    "Sometimes you also just want to parse data line by line yourself. For example, here is a very simple data set of female baby names:\n",
    "\n",
    "http://deron.meranda.us/data/census-dist-female-first.txt\n",
    "\n",
    "Perhaps, we just want to extract all of the names which I have saved to a file in the Git repo. In raw Python we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "with open(\"../small_data/male_names.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        tokens = line.split(\" \")\n",
    "        names.append(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JAMES', 'JOHN', 'ROBERT', 'MICHAEL', 'WILLIAM']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAMES', 1),\n",
       " ('JOHN', 1),\n",
       " ('ROBERT', 1),\n",
       " ('MICHAEL', 1),\n",
       " ('WILLIAM', 1),\n",
       " ('DAVID', 1),\n",
       " ('RICHARD', 1),\n",
       " ('CHARLES', 1),\n",
       " ('JOSEPH', 1),\n",
       " ('THOMAS', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(names).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data from APIs (GET / POST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
